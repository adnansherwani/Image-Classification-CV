{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.utils import io\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device Setup\n",
    "Use parallel computing on GPU in CUDA-capable systems, otherwise - use CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "Local Dataset and Data Loader Functions\n",
    "The CustomImageDataset function is used for fetching images from the [train, test, valid] directories, and storing them in a Dataset object, along with their labels from [train_labels.csv, test_labels.csv, valid_labels.csv,]\n",
    "\n",
    "The create_dataloader function, on the other hand, is used for transforming the Dataset object, converting it into a Tensor datatype, and storing it as a batch-based Dataloader object, ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    load local dataset to a structure recognized by dataloaders\n",
    "    - input labels: Pandas DataFrame\n",
    "    - input img_dir: string, the path to the samples directory\n",
    "    - input transform (optional): a Torch transforms object\n",
    "\n",
    "    - output image: a Pytorch Tensor of samples\n",
    "    - output label: a list of labels\n",
    "    \"\"\"\n",
    "    def __init__(self, labels, img_dir, transform=None):\n",
    "        self.img_labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):      \n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "def create_dataloader(data_dir, batch_size, labels, size=224):\n",
    "    \"\"\"\n",
    "    transforms custom dataset and converts it into a pytorch dataloader object\n",
    "    - input data_dir: string with the path to a data directory\n",
    "    - input batch_size: an integer that represents the batch size\n",
    "    - input labels: Pandas DataFrame that stores the data labels\n",
    "    - input size (optional): sets the final pixel width and height of the samples\n",
    "\n",
    "    - output dataloader: a pytorch dataloader object\n",
    "    \"\"\"\n",
    "    if size == 224:\n",
    "        # resize and crop AlteredNet samples\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    elif size == 512:\n",
    "        # no resizing and cropping required\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    else:\n",
    "        print(\"sorry, only size 224 or 512 can be loaded, please try again\")\n",
    "        transform = None\n",
    "    \n",
    "    # load samples into a custom image dataset\n",
    "    data = CustomImageDataset(labels, data_dir, transform=transform)\n",
    "\n",
    "    # convert custom image dataset into a data loader\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = {i: pd.read_csv(\"D:\\Adnan\\Project Data\\Python Programming\\Image Classification CV\\RealFakeImageClassification\\AlteredNet\\data\\labels\" + i + \"_labels.csv\") for i in [\"train\", \"test\", \"valid\"]}\n",
    "\n",
    "dataloaders = {}\n",
    "\n",
    "dataloaders[\"train\"] = create_dataloader(\"data/train\", 5, label_df[\"train\"], size=224)\n",
    "dataloaders[\"test\"] = create_dataloader(\"data/test\", 5, label_df[\"test\"], size=224)\n",
    "dataloaders[\"valid\"] = create_dataloader(\"data/valid\", 5, label_df[\"valid\"], size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
